{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alshahreyaj/thesis/blob/main/ML%2BVGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3EPQinGms27",
        "outputId": "745af02e-6652-4c27-feaf-6c7a2744797a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll79m1MR23MI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "training_dir = \"/content/drive/MyDrive/Colab Notebooks/Thesis/hemorrhage\"\n",
        "img_dir_list = os.listdir(training_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vZeJxCIpmkIc",
        "outputId": "bdec61f2-5758-4fa7-e8ed-e5d0ef962a84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!pip install pandas\\n!pip install numpy\\n!pip install opencv-python\\n!pip install sklearn'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "'''!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install sklearn'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vnHEBD7umkId",
        "outputId": "cab853d9-fde4-4129-f62c-47ecafe234ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!pip uninstall keras'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "'''!pip uninstall keras'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V49_Ve2h26y2",
        "outputId": "83f06eaf-c267-453e-ae4c-a945c2e0dfc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hemorrhagic', 'Normal']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "img_dir_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBgqthP-nxop"
      },
      "outputs": [],
      "source": [
        "class_names = {'Hemorrhagic': 0, 'Normal': 1}\n",
        "# list file address and class\n",
        "DATA_DF = []\n",
        "for img_dir in img_dir_list:\n",
        "  file_dir = os.listdir(training_dir+\"/\"+img_dir)\n",
        "  for file_name in file_dir:\n",
        "    DATA_DF.append([file_name,class_names[img_dir],img_dir])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fNRVuEtTtpEo",
        "outputId": "618dba4d-2638-4c74-b0b3-e3af093d301e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93814519-6eb5-471f-8046-ab26f5f5f16a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>class</th>\n",
              "      <th>dir</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4990</th>\n",
              "      <td>N25_0_41.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6278</th>\n",
              "      <td>N11_0_68.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5148</th>\n",
              "      <td>N21_0_132.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2341</th>\n",
              "      <td>17_0_108.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>Hemorrhagic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5360</th>\n",
              "      <td>N21_0_78.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93814519-6eb5-471f-8046-ab26f5f5f16a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93814519-6eb5-471f-8046-ab26f5f5f16a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93814519-6eb5-471f-8046-ab26f5f5f16a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          file_name  class          dir\n",
              "4990   N25_0_41.jpg      1       Normal\n",
              "6278   N11_0_68.jpg      1       Normal\n",
              "5148  N21_0_132.jpg      1       Normal\n",
              "2341   17_0_108.jpg      0  Hemorrhagic\n",
              "5360   N21_0_78.jpg      1       Normal"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# convert to pandas data frame\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "Train_Data_Frame = pd.DataFrame(DATA_DF, columns = [\"file_name\",\"class\",\"dir\"])\n",
        "\n",
        "Train_Data_Frame = shuffle(Train_Data_Frame)\n",
        "\n",
        "Train_Data_Frame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HCIhbulqy_x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_data = np.array(to_categorical(Train_Data_Frame[\"class\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Z0XwjkvgXj",
        "outputId": "854eff11-dc56-48e0-cd24-f0494a63f460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(y_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QhtH6Uw1OGh"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "from tensorflow.python.keras.models import Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Djb9021Pqg",
        "outputId": "888f4866-4b44-4e07-c841-3eb2652296fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "base_model = tf.keras.applications.VGG19(include_top=False,weights='imagenet',input_shape=(224, 224, 3))\n",
        "base_model.summary()\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTJmX6f4q33W",
        "outputId": "88ca70bd-2188-46dc-f07b-0f59679c30c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6795/6795 [25:44<00:00,  4.40it/s]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from tqdm import tqdm\n",
        "x_data = []\n",
        "for rows in tqdm(range(len(Train_Data_Frame))):\n",
        "  get_file_name = Train_Data_Frame.iloc[rows]\n",
        "  img = cv2.imread(training_dir+'/'+get_file_name['dir']+'/'+get_file_name['file_name'])\n",
        "  stretch_near = cv2.resize(img, (224, 224),\n",
        "               interpolation = cv2.INTER_AREA)\n",
        "  features = model.predict(stretch_near.reshape(1,224,224,3))\n",
        "  features = features.reshape(25088,)\n",
        "  x_data.append(features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXpUKnxj0MUY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test  = train_test_split(x_data,y_data,train_size=0.9,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIAgcnVhvFFj"
      },
      "source": [
        "### If there is seperate test folder\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "aR-rsXNf0UFu",
        "outputId": "a0780dc1-a416-48c2-bee8-6c3ed340d145"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'testing_dir = \"/content/drive/MyDrive/Colab Notebooks/Image Processing/kidney/Test_images\"\\nimg_dir_list = os.listdir(training_dir)\\nclass_names = {\\'Grade0\\': 0, \\'Grade1\\': 1, \\'Grade3\\': 2, \\'Grade4\\': 3, \\'Grade2\\': 4}\\n# list file address and class\\nDATA_DF = []\\nfor img_dir in img_dir_list:\\n  file_dir = os.listdir(testing_dir+\"/\"+img_dir)\\n  for file_name in file_dir:\\n    DATA_DF.append([file_name,class_names[img_dir],img_dir])\\n\\n# convert to pandas data frame\\nimport pandas as pd\\nfrom sklearn.utils import shuffle\\n\\nTest_Data_Frame = pd.DataFrame(DATA_DF, columns = [\"file_name\",\"class\",\"dir\"])\\n\\nTest_Data_Frame = shuffle(Test_Data_Frame)\\n\\nimport numpy as np\\nfrom keras.utils.np_utils import to_categorical\\ny_test_data = np.array(to_categorical(Test_Data_Frame[\"class\"]))\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "'''testing_dir = \"/content/drive/MyDrive/Colab Notebooks/Image Processing/kidney/Test_images\"\n",
        "img_dir_list = os.listdir(training_dir)\n",
        "class_names = {'Grade0': 0, 'Grade1': 1, 'Grade3': 2, 'Grade4': 3, 'Grade2': 4}\n",
        "# list file address and class\n",
        "DATA_DF = []\n",
        "for img_dir in img_dir_list:\n",
        "  file_dir = os.listdir(testing_dir+\"/\"+img_dir)\n",
        "  for file_name in file_dir:\n",
        "    DATA_DF.append([file_name,class_names[img_dir],img_dir])\n",
        "\n",
        "# convert to pandas data frame\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "Test_Data_Frame = pd.DataFrame(DATA_DF, columns = [\"file_name\",\"class\",\"dir\"])\n",
        "\n",
        "Test_Data_Frame = shuffle(Test_Data_Frame)\n",
        "\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_test_data = np.array(to_categorical(Test_Data_Frame[\"class\"]))\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ea1S7bMO1SuF",
        "outputId": "45827419-dba2-42dd-b63e-ec047148a184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import cv2\\nfrom tqdm import tqdm\\nx_test_data = []\\nfor rows in tqdm(range(len(Test_Data_Frame))):\\n  get_file_name = Test_Data_Frame.iloc[rows]\\n  img = cv2.imread(testing_dir+'/'+get_file_name['dir']+'/'+get_file_name['file_name'])\\n  stretch_near = cv2.resize(img, (224, 224),\\n               interpolation = cv2.INTER_AREA)\\n  features = model.predict(stretch_near.reshape(1,224,224,3))\\n  features = features.reshape(2048,)\\n  x_test_data.append(features)\""
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "'''import cv2\n",
        "from tqdm import tqdm\n",
        "x_test_data = []\n",
        "for rows in tqdm(range(len(Test_Data_Frame))):\n",
        "  get_file_name = Test_Data_Frame.iloc[rows]\n",
        "  img = cv2.imread(testing_dir+'/'+get_file_name['dir']+'/'+get_file_name['file_name'])\n",
        "  stretch_near = cv2.resize(img, (224, 224),\n",
        "               interpolation = cv2.INTER_AREA)\n",
        "  features = model.predict(stretch_near.reshape(1,224,224,3))\n",
        "  features = features.reshape(2048,)\n",
        "  x_test_data.append(features)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pFXanNuJ1x02",
        "outputId": "0496f61f-6e90-4564-aadc-9d939fda94d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x_test, y_test = x_test_data, y_test_data'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "'''x_test, y_test = x_test_data, y_test_data'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AD9nLDoevgmc",
        "outputId": "8173b1ae-0f47-40da-eb04-6cd0e6438b0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'x_train,y_train = x_data, y_data'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'''x_train,y_train = x_data, y_data'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TaQSWAhrDMV"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWBIw7xcOYmY"
      },
      "source": [
        "#### Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Upe1n-FMOSzJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initializing Classifiers\n",
        "clf1 = LogisticRegression(multi_class='multinomial',\n",
        "                          solver='newton-cg',\n",
        "                          random_state=1)\n",
        "clf2 = KNeighborsClassifier(algorithm='ball_tree',\n",
        "                            leaf_size=50)\n",
        "clf3 = DecisionTreeClassifier(random_state=1)\n",
        "clf4 = SVC(random_state=1)\n",
        "clf5 = RandomForestClassifier(random_state=1)\n",
        "clf6 = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
        "                    silent=True, nthread=1)\n",
        "clf7 = GradientBoostingClassifier()\n",
        "# Building the pipelines\n",
        "pipe1 = Pipeline([('std', StandardScaler()),\n",
        "                  ('clf1', clf1)])\n",
        "\n",
        "pipe2 = Pipeline([('std', StandardScaler()),\n",
        "                  ('clf2', clf2)])\n",
        "\n",
        "pipe4 = Pipeline([('std', StandardScaler()),\n",
        "                  ('clf4', clf4)])\n",
        "\n",
        "\n",
        "\n",
        "# Setting up the parameter grids\n",
        "param_grid1 = [{'clf1__penalty': ['l2'],\n",
        "                'clf1__C': np.power(10., np.arange(-4, 4))}]\n",
        "\n",
        "param_grid2 = [{'clf2__n_neighbors': list(range(1, 10)),\n",
        "                'clf2__p': [1, 2]}]\n",
        "\n",
        "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],\n",
        "                'criterion': ['gini', 'entropy']}]\n",
        "\n",
        "param_grid4 = [{'clf4__kernel': ['rbf'],\n",
        "                'clf4__C': np.power(10., np.arange(-4, 4)),\n",
        "                'clf4__gamma': np.power(10., np.arange(-5, 0))},\n",
        "               {'clf4__kernel': ['linear'],\n",
        "                'clf4__C': np.power(10., np.arange(-4, 4))}]\n",
        "\n",
        "param_grid5 = [{'n_estimators': [10, 100, 500, 1000]}]\n",
        "\n",
        "param_grid6 = [{\n",
        "        'min_child_weight': [1, 5, 10],\n",
        "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
        "        'subsample': [0.6, 0.8, 1.0],\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "        'max_depth': [3, 4, 5]\n",
        "        }]\n",
        "\n",
        "param_grid7 = {\n",
        "    \"n_estimators\":[5,50,250,500],\n",
        "    \"max_depth\":[1,3,5,7,9],\n",
        "    \"learning_rate\":[0.01,0.1,1]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-OxPPFKPqSC"
      },
      "outputs": [],
      "source": [
        "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
        "gridcvs = {}\n",
        "inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
        "\n",
        "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3, param_grid4, param_grid5,param_grid6,param_grid7),\n",
        "                            (pipe1, pipe2, clf3, pipe4, clf5,clf6,clf7),\n",
        "                            ('Softmax', 'KNN', 'DTree', 'SVM', 'RForest','Xgboost','GradientBoosting')):\n",
        "    gcv = GridSearchCV(estimator=est,\n",
        "                       param_grid=pgrid,\n",
        "                       scoring='accuracy',\n",
        "                       n_jobs=-1,\n",
        "                       cv=inner_cv,\n",
        "                       verbose=0,\n",
        "                       refit=True)\n",
        "    gridcvs[name] = gcv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "g9xbkRk5P4rV",
        "outputId": "d95a4ba1-3610-461b-fec4-fb7330c4f16b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"for name, gs_est in sorted(gridcvs.items()):\\n        gridcvs[name].fit(np.array(x_train),np.argmax(y_train,axis=1)) # run inner loop hyperparam tuning\\n        print(name+':')\\n        print('\\n        Best ACC (avg. ) %.2f%%' % (gridcvs[name].best_score_ * 100))\\n        print('        Best parameters:', gridcvs[name].best_params_)\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "'''for name, gs_est in sorted(gridcvs.items()):\n",
        "        gridcvs[name].fit(np.array(x_train),np.argmax(y_train,axis=1)) # run inner loop hyperparam tuning\n",
        "        print(name+':')\n",
        "        print('\\n        Best ACC (avg. ) %.2f%%' % (gridcvs[name].best_score_ * 100))\n",
        "        print('        Best parameters:', gridcvs[name].best_params_)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXi9cO7fZvJf"
      },
      "source": [
        "#### Model Training \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCDgBpBKzIR5"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "xb = xgb.XGBClassifier()\n",
        "svm = SVC(kernel='rbf')\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
        "\n",
        "classifiers = {\"svm\": svm, \"xboost\": xb, \"Gradientboosting\": gbm}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TWrRMjVpW8v"
      },
      "outputs": [],
      "source": [
        "# demonstration of calculating metrics for a neural network model using sklearn\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from numpy import mean\n",
        "from numpy import std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB-YkgyQ-tUD",
        "outputId": "ce82a8a3-d712-4b63-fffe-0ba3a18003ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6115, 25088)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "np.array(x_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OouqXkEQ-3TQ",
        "outputId": "1b011d1b-84ff-4265-86cc-66c50626c166"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6115,)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "np.argmax(y_train, axis=1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wbCRufLEJ2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16de144e-8cdb-4229-ea20-5082ab1be4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svm :\n",
            "Training Score: 0.9993458708094849\n",
            "Testing Score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [20:14<40:29, 1214.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.000000\n",
            "Recall: 1.000000\n",
            "F1 score: 1.000000\n",
            "Cohens kappa: 1.000000\n",
            "[[255   0]\n",
            " [  0 425]]\n",
            "xboost :\n",
            "Training Score: 0.996238757154538\n",
            "Testing Score: 0.9911764705882353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [26:08<11:47, 707.98s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.991181\n",
            "Recall: 0.991176\n",
            "F1 score: 0.991169\n",
            "Cohens kappa: 0.981147\n",
            "[[251   4]\n",
            " [  2 423]]\n",
            "Gradientboosting :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [37:22<00:00, 747.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Score: 0.9934587080948487\n",
            "Testing Score: 0.961764705882353\n",
            "Precision: 0.961765\n",
            "Recall: 0.961765\n",
            "F1 score: 0.961765\n",
            "Cohens kappa: 0.918431\n",
            "[[242  13]\n",
            " [ 13 412]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for d in tqdm(classifiers):\n",
        "  classifier = classifiers[d]\n",
        "  print(d+\" :\")\n",
        "  cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "  #scores = cross_val_score(classifier, np.array(x_train),np.argmax(y_train,axis=1), scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  # report performance\n",
        "  #print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
        "  classifier.fit(np.array(x_train),np.argmax(y_train,axis=1))\n",
        "  training_score = classifier.score(np.array(x_train),np.argmax(y_train,axis=1))\n",
        "  print(\"Training Score: \"+str(training_score))\n",
        "  testing_score = classifier.score(np.array(x_test),np.argmax(y_test,axis=1))\n",
        "  print(\"Testing Score: \"+str(testing_score))\n",
        "  yhat_classes = classifier.predict(np.array(x_test))\n",
        "  # precision tp / (tp + fp)\n",
        "  precision = precision_score(np.argmax(y_test, axis=1),yhat_classes, average='weighted')\n",
        "  print('Precision: %f' % precision)\n",
        "  # recall: tp / (tp + fn)\n",
        "  recall = recall_score(np.argmax(y_test, axis=1),yhat_classes, average='weighted')\n",
        "  print('Recall: %f' % recall)\n",
        "  # f1: 2 tp / (2 tp + fp + fn)\n",
        "  f1 = f1_score(np.argmax(y_test, axis=1),yhat_classes, average='weighted')\n",
        "  print('F1 score: %f' % f1)\n",
        "  # kappa\n",
        "  kappa = cohen_kappa_score(np.argmax(y_test, axis=1),yhat_classes)\n",
        "  print('Cohens kappa: %f' % kappa)\n",
        "  # ROC AUC\n",
        "  #auc = roc_auc_score(np.argmax(y_test, axis=1),yhat_classes,multi_class=\"ovo\", average='weighted')\n",
        "  #print('ROC AUC: %f' % auc)\n",
        "  # confusion matrix\n",
        "  matrix = confusion_matrix(np.argmax(y_test, axis=1),yhat_classes)\n",
        "  print(matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WOGxGpqmkIp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}